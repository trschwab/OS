Troy Schwab

1.1 
What type(s) of fragmentation is (are) possible with a custom memory allocator like yours? Internal, external or yet something different?

Internal and external are both possible but because I do not join nodes in free_list then it is possible for me to have n amount of nodes of size 1 byte with a list of n size.

1.2
Propose two or more performance metrics (unrelated to fragmentation) that you could use to assess how well your memory allocator works and describe how you could measure each one.

The first metric could probably be the time it takes to make a list and fill it and remove it with n nodes, and the second metric could be the largest sized lists that I can actually create and how that would affect performance of the time.

1.3 
Algorithm for average fragmentation calculation:

avg{
    max
    total
    i = allocated->front
    while i != NULL {
        if i->size > max{
            max = i->size
        }
        total += i->size
        i = i->next
    }
    return (total - max) / total
}

2.1
Is this algorithm appropriate to bring your allocator to a state where you can have a representative amount of fragmentation?
this algorithm referencing:

srandom(seed)
int r = 0
void *p = NULL
while (r < requests) {
	s = random number between 0 and 1000;
	p = allocate (algorithm, s)
	deallocate(p)

No, this is because just allocating and then deallocating a node will result in 0 fragmentation. You have to deallocate a node that is not the most recently allocated. To solve this there is a list of requests that gets filled with nodes and the deallocate node is randomly picked from that one using rand().
Changed algorithm:

main {
    int alg
    int seed
    int requests
    dnode *list[requests] init to NULL
    
    srand(seed)

    r = 0
    int s
    int d
    dnode *p = NULL

    init allocator

    while (r < requests) {
        s = rand between 100 and 1000
        d = s % requests
        p = allocate(s)
        if(list[d] != null)
            deallo(list[d])
            list[d] = null
    }
    r++
}

3.2
Reflect upon the data you obtained and use it to argue which allocation policy works best for your simulation of allocation/deallocation activity. In answers.txt, write a conjecture of your own to explain why this policy worked better than the others.

First fit worked best or algorithm 0, as it had the tightest interval over 50 trials. I assume this is the case because to deallocate is to remove the first node, arbitrary of size, ergo external fragmentation will be reduced. This is stark against worst and best which have minimum measures against internal fragmentation.

